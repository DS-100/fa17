{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install SQL packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !conda install -y psycopg2\n",
    "# !conda install -y postgresql\n",
    "# !pip install ipython-sql\n",
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard imports + sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a database connection to the Postgres database running on my machine `localhost` using the schema `ds100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postgresql_uri = \"postgres://jegonzal:@localhost:5432/ds100\"\n",
    "sqlite_uri = \"sqlite:///data/ds100.db\"\n",
    "default_db = postgresql_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "-- Need to drop views to prevent integrity constraint violations later.\n",
    "DROP VIEW IF EXISTS date_stats;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Table Creation, Manipulation, and Queries\n",
    "\n",
    "The following example works through some basic table operations including:\n",
    "\n",
    "1. creating a table\n",
    "1. adding rows\n",
    "1. updating rows\n",
    "1. deleting rows\n",
    "1. querying the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CREATE TABLE` and `DROP TABLE`\n",
    "\n",
    "To start, we are going to define a toy *relation* (a.k.a. *table*), populate it with some toy data, and work through some basic SQL. Deeper stuff coming soon though, I promise!\n",
    "\n",
    "First, let's create the table of students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "-- Drop the table if it already exists\n",
    "DROP TABLE IF EXISTS students;\n",
    "\n",
    "-- Create the table profs\n",
    "CREATE TABLE students(\n",
    "    name TEXT PRIMARY KEY, \n",
    "    gpa FLOAT CHECK (gpa >= 0.0 and gpa <= 4.0), \n",
    "    age INTEGER, \n",
    "    dept TEXT, \n",
    "    gender CHAR);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each column has a fixed data type.\n",
    "\n",
    "**The DBMS will enforce these types as data is inserted.**\n",
    "\n",
    "Note also the definition of a primary key, as we discussed in the EDA lecture. \n",
    "\n",
    "**The DBMS will enforce the uniqueness of values in the key columns.**\n",
    "\n",
    "To see what we've done, let's run our first query, dumping out the content of the table: every column for each row. We denote every column with `*`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT * FROM students;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If this is funny you are *Getting IT*\n",
    "\n",
    "![Boby Drop tables](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)\n",
    "\n",
    "... it's funny, believe me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  INSERTing VALUES\n",
    "Now let's manually insert some values into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "INSERT INTO students VALUES \n",
    " ('Sergey Brin', 2.8, 40, 'CS', 'M'),\n",
    "  ('Danah Boyd', 3.9, 35, 'CS', 'F'),\n",
    "  ('Bill Gates', 1.0, 60, 'CS', 'M'),\n",
    "  ('Hillary Mason', 4.0, 35, 'DATASCI', 'F'),\n",
    "  ('Mike Olson', 3.7, 50, 'CS', 'M'),\n",
    "  ('Mark Zuckerberg', 4.0, 30, 'CS', 'M'),\n",
    "  ('Cheryl Sandberg', 4.0, 47, 'BUSINESS', 'F'),\n",
    "  ('Susan Wojcicki', 4.0, 46, 'BUSINESS', 'F'),\n",
    "  ('Marissa Meyer', 4.0, 45, 'BUSINESS', 'F');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that strings in SQL must be quoted with a single quote **`'`** character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how insertions need to have values in the same order as the columns in the `create table` statement! Let's make sure our data is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT * FROM students;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Key Integrity Constraint\n",
    "\n",
    "What happens if we try to insert another record with the same primary key (`name`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%sql $default_db\n",
    "# INSERT INTO students VALUES ('Bill Gates', 4.0, 60, 'BUSINESS', 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can populate the database using Pandas as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df = sns.load_dataset(\"tips\")\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a connection with the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(default_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the table if it already exists and then upload the table to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = engine.execute(\"DROP TABLE IF EXISTS tips;\")\n",
    "with engine.connect() as conn:\n",
    "    tips_df.to_sql(\"tips\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also download tables directly into pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    students = pd.read_sql(\"SELECT * FROM students\", conn)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Schema\n",
    "\n",
    "There is no mechanism in standard SQL to access the schema associated with each database management systems.  Here we use the corresponding client tools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sqlite3 schema information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 data/ds100.db \".schema students\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **PostgreSQL schema information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"\\d students\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Using SQL Alchemy's Generic Driver**\n",
    "\n",
    "I found the following [SQL Alchemy Quick Reference Sheet](https://www.pythonsheets.com/notes/python-sqlalchemy.html) to be very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(postgresql_uri)\n",
    "inspector = sqlalchemy.inspect(engine)\n",
    "for col in inspector.get_columns(\"students\"):\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(sqlite_uri)\n",
    "inspector = sqlalchemy.inspect(engine)\n",
    "for col in inspector.get_columns(\"students\"):\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDATE values\n",
    "\n",
    "What is Bill Gates' GPA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT * FROM students\n",
    "    WHERE name LIKE  '%Bill%' -- SQL like regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, Bill has a low GPA let's lend him a hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "UPDATE students\n",
    "    SET gpa = 1.0 + gpa\n",
    "    WHERE LOWER(name) = 'bill gates';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's check the table now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT * FROM students\n",
    "    WHERE name ~'^Bil.'; -- Regular expression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose Mark logged into the database and tried to give himself a 5.0?  Uncomment the following line to see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%sql \n",
    "\n",
    "# UPDATE students\n",
    "#     SET gpa = 1.0 + gpa\n",
    "#     WHERE LOWER(name) LIKE '%zuck%';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code fails.  Why? (check the gpa.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT * FROM students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice two things: \n",
    "1. If you are using Postgres the rows likely came back in a **different order** than before.  Remember: relations do not have a defined order, and in fact two different orders are just two ways of describing the same relation!\n",
    "2. Note the relational style of the `update` statement: **we decide which rows get updated based entirely on the values in each row, as checked by the `where` clause.** There is no notion of any information outside the values in the row--e.g. there are no \"object identifiers\" or \"row numbers\"... everything is *just the data and only the data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can delete rows in much the same way we update rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "DELETE FROM students \n",
    "    WHERE name = 'Sergey Brin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT * FROM students;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restoring Sergey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "INSERT INTO students VALUES\n",
    "      ('Sergey Brin', 4.0, 40, 'CS', 'M');\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT Queries\n",
    "\n",
    "Now let's start looking at some slightly more interesting queries.  The canonical SQL query block includes the following clauses, in the order they appear. Square brackets indicate optional clauses.\n",
    "\n",
    "```sql\n",
    "SELECT ...\n",
    "  FROM ...\n",
    "[WHERE ...]\n",
    "[GROUP BY ...]\n",
    "[HAVING ...]\n",
    "[ORDER BY ...]\n",
    "[LIMIT ...];\n",
    "```\n",
    "\n",
    "Query blocks can reference one or more tables, and be nested in various ways.  Before we worry about multi-table queries or nested queries, we'll work our way through examples that exercise all of these clauses on a single table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `SELECT` LIST\n",
    "\n",
    "The `SELECT` list determines which columns to include in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT name\n",
    "FROM students;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions in the Selection List\n",
    "\n",
    "SQL has a wide range of functions that can be applied to each attribute in the select list.  Notice that we can alias (name) the columns with `AS`.  The complete list of built in [PostreSQL functions is available here](https://www.postgresql.org/docs/9.2/static/functions.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT UPPER(name) AS n, LOWER(dept) as d, gpa * 4.0 AS four_gpa\n",
    "FROM students;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Distinct Rows \n",
    "\n",
    "As we know, SQL is a multiset logic, preserving the meaning of the number of duplicates in query results. Sometimes, however, we don't want to keep the duplicates, we want to eliminate them.  This is done simply by adding the keyword `DISTINCT` after the `SELECT` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT DISTINCT dept\n",
    "    FROM students\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which rows are used when taking the distinct entries?  Does it really matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `WHERE` Clause\n",
    "\n",
    "The `WHERE` clause determines which *rows* of to include by specifying a predicate (boolean expression).  Rows (tuples) that satisfy this expression are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT name, gpa\n",
    "    FROM students\n",
    "    WHERE dept = 'CS'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we can specify both rows and columns explicitly. If we have a primary key, we can filter things down to even the cell level via a `select` list of one column, and a `where` clause checking equality on the primary key columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT gpa\n",
    "FROM students\n",
    "WHERE name = 'Bill Gates';\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even this **\"single-celled\"** response still has a uniform data type of a *relation*. \n",
    "\n",
    "\n",
    "**SQL is Closed Over Tables**:\n",
    "SQL expressions take in tables and always produce tables.  How does this compare to Pandas?\n",
    "\n",
    "\n",
    "Now that you can slice and dice tables into columns, rows and cells, you have enough knowledge to poke around in a database. Let's move on to skills that you'll need as a data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GROUP BY aggregation in SQL is a lot like the group by in Pandas.  SQL provides a family of [*aggregate functions*] for use in the `select` clause. In the simplest form, queries with aggregates in the `select` clause generate a single row of output, with each aggregate function performing a summary of all the rows of input. You can have many aggregate functions in your `select` clause:\n",
    "\n",
    "A list of built-in aggregate functions in PostgreSQL is [here](https://www.postgresql.org/docs/current/static/functions-aggregate.html). In our case, the query we are looking for is as follows. \n",
    "\n",
    "In the following we compute the average GPA as well as the number of students in each department:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT dept, AVG(gpa) as avg_gpa, COUNT(*)\n",
    "    FROM students\n",
    "    GROUP BY dept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **`HAVING`** clause to apply a predicate to groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT dept, AVG(gpa) as avg_gpa, COUNT(*)\n",
    "    FROM students\n",
    "    GROUP BY dept\n",
    "    HAVING COUNT(*) >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql  $default_db\n",
    "\n",
    "SELECT dept, AVG(gpa) as avg_gpa, COUNT(*)\n",
    "    FROM students\n",
    "    WHERE gender = 'F'\n",
    "    GROUP BY dept\n",
    "    HAVING COUNT(*) >= 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering the output\n",
    "As a nicety, SQL allows you to order your output rows, in either ascending (ASC) or descending (DESC) order of the values in columns. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT *\n",
    "FROM students\n",
    "ORDER BY gpa;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT *\n",
    "FROM students\n",
    "ORDER BY gpa, age;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $default_db\n",
    "\n",
    "SELECT *\n",
    "FROM students\n",
    "ORDER BY gpa DESC, age ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMIT Clause\n",
    "\n",
    "The limit clause limits the number of elements returned.  Which elements are returned? While this depends on the order of elements which could be arbitrary beyond anything specified by the `ORDER BY` clauses.\n",
    "\n",
    "Is this a random sample?  NO\n",
    "\n",
    "\n",
    "Why do we use the `LIMIT` clause?  Often the database we are querying is massive and retrieving the entire table as we are debugging the query can be costly in time and system resources.  However, we should avoid using `LIMIT` when constructing a sample of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM students LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "\n",
    "It is often assumed that when working with a database all relations (tables) must come from outside or be derived from other sources of data.  It is possible to construct tables in SQL.\n",
    "\n",
    "Sometimes it's useful to auto-generate data in queries, rather than examine data in the database. This is nice for testing, but also can be useful to play some computational tricks as you'll see in your homework.\n",
    "\n",
    "SQL has a simple scalar function called [`random`](https://www.postgresql.org/docs/9.6/static/functions-math.html#FUNCTIONS-MATH-RANDOM-TABLE) that returns a random value between 0.0 and 1.0. You can use this if you need to generate a column of random numbers.  (The PostgreSQL manual doesn't promise much about the statistical properties of this random number generator.)\n",
    "\n",
    "Let's roll a 6-sided die for each of the students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT *, ROUND(RANDOM() * 6) as roll_dice \n",
    "FROM students;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this a good implementation of a fair 6 sided die?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to generate a whole bunch of random numbers, not tied to any particular stored table -- can we do that in SQL?\n",
    "\n",
    "SQL has a notion of [table-valued functions](https://www.postgresql.org/docs/9.6/static/functions-srf.html): functions that return tables, and hence can be used in a `FROM` clause of a query. The standard table-valued function is called `generate_series`, and it's much like numpy's `arange`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT * \n",
    "FROM generate_series(1,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT * \n",
    "FROM generate_series(1,10, 2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to generate 5 random real numbers between 0 and 6, we might use this SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT trial, (6*RANDOM()) AS rando\n",
    "FROM generate_series(1, 5) AS flip(trial);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the distribution of our earlier generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "\n",
    "SELECT ROUND(6*RANDOM()) AS rando, COUNT(*)\n",
    "FROM generate_series(1, 100000) AS flip(trial)\n",
    "GROUP BY rando\n",
    "ORDER BY count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want integers, we can use a PostgreSQL typecast operator (postfix `::<type>`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "-- NOTE WE ALSO TAKE THE CEIL \n",
    "\n",
    "SELECT CEIL(6*RANDOM())::INTEGER AS rando, COUNT(*)\n",
    "FROM generate_series(1, 100000) AS flip(trial)\n",
    "GROUP BY rando\n",
    "ORDER BY count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Random Matrix in SQL?!\n",
    "\n",
    "Now suppose we want to populate a \"matrix\" relation `my_matrix(x, y, val)` full of random values. In Python during Lecture 7 we used `np.random.randn(3,2)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# normally distributed random numbers, mean 0 variance 1\n",
    "np.random.randn(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this relational version we need to explicitly generate the `x` and `y` values. We can do this via SQL's built-in cartesian product!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT rows.x, columns.y, random() AS val\n",
    "  FROM generate_series(0,2) AS rows(x),\n",
    "       generate_series(0,1) AS columns(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to store a matrix as a tableâ€”in which case we should set up the schema properly to ensure that it remains a legal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "DROP TABLE IF EXISTS my_matrix;\n",
    "\n",
    "CREATE TABLE my_matrix(x INTEGER, y INTEGER, val FLOAT, PRIMARY KEY(x,y));\n",
    "\n",
    "INSERT INTO my_matrix\n",
    "SELECT rows.x, columns.y, random() AS val\n",
    "  FROM generate_series(0,2) AS rows(x),\n",
    "       generate_series(0,1) AS columns(y);\n",
    "        \n",
    "SELECT * FROM my_matrix;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few take-aways from the previous cell:\n",
    "- Notice the schema of `my_matrix` reflects the fact that `val` is a function of the row (`x`) and column (`y`) IDs.\n",
    "- We've said before that the order of rows in a table isn't defined in SQL. Is this relational representation of a \"matrix\" faithful to the mathematical definition of a matrix? Why or why not?\n",
    "- Notice the `INSERT` statement, which contains a `SELECT` query rather than the `VALUES` we saw before. You might want to experiment and see what would happen if the `SELECT` query produces a different schema than `my_matrix`: try having it produce too few columns, too many columns, columns in different orders, etc.\n",
    "- In the `INSERT...SELECT` statement, notice the definition of output column names via the `AS` in the `SELECT` clause. Is that necessary here?\n",
    "- In the `INSERT...SELECT` statement, notice the definition of table *and* column names in the `FROM` clause via `AS`, and the way they get referenced in the `SELECT` clause. Do we need the tablenames specified in the `SELECT` clause? Try it and see!\n",
    "- Count the rows in the output...does it look good?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-defined functions (UDFs)\n",
    "Sometimes we may want a custom scalar function that isn't built into SQL. Some database systems allow you to register your own *user-defined functions* (UDFs) in one or more programming languages. Conveniently, PostgreSQL allows us to register user-defined functions written in Python. Be aware of two things:\n",
    "\n",
    "1. Calling Python for each row in a query is quite a bit slower than using the pre-compiled built-in functions in SQL ... this is akin to the use of Python loops instead of `numpy` calls. *If you can avoid using Python UDFs you should do so to get better performance*.\n",
    "\n",
    "2. Python is a full-feature programming language with access to your operating system's functionality, which means it can reach outside of the scope of the query and wreak havoc, including running arbitrary UNIX commands. (PostgreSQL refers to this as an `untrusted` language.) Be *very* careful with the Python UDFs you use in your Postgres queries! If you want to be safer write UDFs in a trusted language. PostgreSQL has a [number of other languages](https://www.postgresql.org/docs/current/static/xplang.html) to choose from, including [Java](https://www.postgresql.org/docs/current/static/external-pl.html) and even [R](https://www.postgresql.org/docs/current/static/external-pl.html)!.\n",
    "\n",
    "First we tell PostgreSQL we want to use the plpythonu package (so named because of \"pl\" for \"programming language\", \"u\" for \"untrusted\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "CREATE EXTENSION IF NOT EXISTS plpythonu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write some trivial Python code and register it as a UDF using the `create function` command. Since SQL is a typed language, we need to specify the SQL types for the input and output to our function, in addition to the code (within $$ delimiters) and the language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "DROP FUNCTION IF EXISTS fib(x INTEGER);\n",
    "\n",
    "CREATE FUNCTION fib(x INTEGER) RETURNS INTEGER\n",
    "AS $$\n",
    "def fib(x):\n",
    "    if x < 2:\n",
    "        return x\n",
    "    else:\n",
    "        return fib(x-1) + fib(x-2)\n",
    "return fib(x)\n",
    "$$ LANGUAGE plpythonu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT x, fib(x)\n",
    "FROM generate_series(1,10) AS row(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Discussion on Transactions\n",
    "\n",
    "It is possible to create transactions that isolate changes.  This is done by starting a transaction with `BEGIN`.  We can then proceed to make changes to the database.  During this time others will not be able to see our changes. Until we end the transactions by saying `ROLLBACK` or `COMMIT`:\n",
    "\n",
    "```sql\n",
    "BEGIN;\n",
    "\n",
    "UPDATE profs SET luckynumber = 888 WHERE lastname = 'Gonzalez';\n",
    "\n",
    "SELECT * FROM profs;\n",
    "\n",
    "ROLLBACK;\n",
    "\n",
    "SELECT * FROM profs;\n",
    "```\n",
    "\n",
    "Try running this in the postgres shell...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Descriptive Statistics in SQL\n",
    "\n",
    "\n",
    "Statistics doesn't deal with individuals, it deals with groups: distributions, populations, samples and the like. As such, computing statistics in SQL focuses heavily on aggregation functions.\n",
    "\n",
    "All SQL systems have simple descriptive statistics built in as aggregation functions:\n",
    "- `min, max`\n",
    "- `count`\n",
    "- `sum`\n",
    "- `avg`\n",
    "- `stddev` and `variance`, the sample standard deviation and variance.\n",
    "\n",
    "PostgreSQL offers [many more](https://www.postgresql.org/docs/current/static/functions-aggregate.html#FUNCTIONS-AGGREGATE-STATISTICS-TABLE). Some handy ones include\n",
    "- `stddev_pop` and `var_pop`: the population standard deviation and variance, which you should use rather than `stddev` and `variance` if you know your data is the full population, not a sample.\n",
    "- `covar_samp` and `covar_pop`: sample and population covariance\n",
    "- `corr`, Pearson's correlation coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Statistics: Aggregates requiring ordered input\n",
    "You'll notice that a number of handy statistics are missing from this list, including the median and quartiles. That's because those are [order statistics](https://en.wikipedia.org/wiki/Order_statistic): they are defined based on an ordering of the values in a column. \n",
    "\n",
    "SQL provides for this by allowing what it calls \"ordered set functions\", which require a `WITHIN GROUP (ORDER BY <columns>)` clause to accompany the order-statistic aggregate.  For example, to compute the 25th percentile, 50th percentile (median) and 75th percentile in SQL, we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT \n",
    "    percentile_cont(0.5) WITHIN GROUP (ORDER BY x) \n",
    "FROM generate_series(1,10) AS data(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two versions of the percentile function:\n",
    "* **`percentile_cont`** inuous : interpolates\n",
    "* **`percentile_disc`** rete : returns an entry from the table\n",
    "\n",
    "What will the following expressions return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT \n",
    "    percentile_disc(0.5) WITHIN GROUP (ORDER BY x) \n",
    "FROM generate_series(1,10) AS data(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the edges and middle of the box in a box plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "SELECT \n",
    "    percentile_disc(0.25) WITHIN GROUP (ORDER BY x) as lower_quartile,\n",
    "    percentile_disc(0.5) WITHIN GROUP (ORDER BY x) as median,\n",
    "    percentile_disc(0.75) WITHIN GROUP (ORDER BY x) as upper_quartile\n",
    "FROM generate_series(1,10) AS data(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Real Data in `psql`\n",
    "In a separate notebook (`load_fec.ipynb`) you'll find the commands to load publicly-available campaign finance [data from the Federal Election Commission](http://www.fec.gov/finance/disclosure/ftpdet.shtml#a2015_2016) into a PostgreSQL database.\n",
    "\n",
    "To see what we have in the database, it's simplest to use the PostgreSQL shell command `psql` to interact with the database.  You can run `man psql` to learn more about it. A few handy tips:\n",
    "1. `psql` supports some useful non-SQL \"meta-\"commands, which you access via backslash (`\\`). To find out about them, run `psql` in a bash shell, and at the prompt you can type `\\?`.\n",
    "2. `psql` has builtin documentation for SQL. To see that, at the `psql` prompt type `\\help`.\n",
    "3. `psql` is an interactive SQL shell, so not suitable for use inside a Jupyter notebook. If you want to invoke it within a Jupyter notebook, you should use `!psql -c <SQL statement>` -- the `-c` flag tells psql to run the SQL statement and then exit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"select * from students;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what tables we have our database after loading the FEC data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"\\d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's have a look at the `individual` table's schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"\\d individual\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about the meaning of these columns check out the [FEC data description](http://classic.fec.gov/finance/disclosure/metadata/DataDictionaryContributionsbyIndividuals.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT COUNT(*)\n",
    "FROM individual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing Tables: `LIMIT` and sampling\n",
    "*This is not the first topic usually taught in SQL, but it's extremely useful for exploration.*\n",
    "\n",
    "OK, now we have some serious data loaded and we're ready to explore it.\n",
    "\n",
    "Database tables are often big--hence the use of a database system. When browsing them at first, we may want to look at exemplary rows: e.g., an arbitrary number of rows, or a random sample of the rows.\n",
    "\n",
    "To look at all of the data in the `individual` table, we would simply write:\n",
    "\n",
    "```sql\n",
    "select * \\\n",
    "  from individual;\n",
    "```\n",
    "\n",
    "But that would return ** *20,347,829* ** rows into our Jupyter notebook's memory, and perhaps overflow the RAM in your computer.  Instead, we could limit the size of the output to the first 3 rows as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT *\n",
    "FROM individual \n",
    "LIMIT 4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### Some notes on the `limit` clause:\n",
    "\n",
    "1. Not only does it **produce a small output**, it's **quite efficient**: the database system **stops iterating over the table after producing the first three rows**, saving the work of examining the other nearly 40 million rows. \n",
    "1. Recall that **relations have no intrinsic order**, so this is **some arbitrary choice of 3 rows**. Two issues to keep in mind:\n",
    "    1. This is a **biased choice of rows**. Very likely these are the first 3 rows stored in some disk file managed by the database, which may (for example) be the first 3 rows that were entered into the database, so they may not be representative of rows entered later.\n",
    "    1. The **result is non-deterministic**. Given that tables are not guaranteed to have an intrinsic order, it is considered correct for an SQL engine to return *any* 3 rows that satisfy this query, and return a different 3 rows each time depending on the cached data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Bernoulli Sample\n",
    "\n",
    "As data scientists, we should be concerned about spending much time looking at a biased subset of our data. Instead, we might want an i.i.d. random sample of the rows in the table. There are various methods for sampling from a table. A simple one built into many database systems including PostgreSQL is [Bernoulli](https://en.wikipedia.org/wiki/Bernoulli_sampling) sampling, in which the decision to return each row is made randomly and independently. As a metaphor, the database engine \"flips a coin\" for each row to decide whether to return it. We can influence the sampling rate by choosing the probability of a \"true\" result of the coinflip. \n",
    "\n",
    "This is done on a per-table basis in the `FROM` clause of the query like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "SELECT *\n",
    "FROM individual TABLESAMPLE BERNOULLI(.00001) REPEATABLE(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the `TABLESAMPLE` clause checkout out the [select docs](https://www.postgresql.org/docs/10/static/sql-select.html).  Note that there is a second sampling method called block sampling which is a lot like cluster sampling at the level of pages on disk!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three things to note relative to our previous `limit` construct:\n",
    "\n",
    "1. **Bernoulli sampling is slow**: it scales linearly with the table size by iterating through every row in the table.\n",
    "1. The **number of rows returned by Bernoulli sampling is probabilistic**. For a table with $n$ rows and a sampling probability $p$, the output size comes from a [binomial distribution]() with mean $np$ and variance ($np(1-p)$). For a very small $p$, the variance means we could easily get 0 rows back when trying our query!\n",
    "1. If we don't know the size of the table, **it's hard to choose a practical sampling probability**. First we want to count up the number of rows $n$ (see the discussion of aggregation queries below), to inform us of a good $p$ to choose to get our desired output size. That means yet another full pass of the table to compute the count before we compute the sample!\n",
    "\n",
    "For these reasons, if we want a proper i.i.d sample, **it's a good idea to compute a nice-sized sample and store it**, keeping it reasonably large for more general use. Since we will not be updating and rows in our `individual` table, we can do this without worrying that the sample will get \"out of date\" with respect to the context of `individual`.  \n",
    "\n",
    "We can use the `CREATE TABLE AS SELECT ...` (a.k.a. CTAS) pattern to do create a table that saves the output of a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "DROP TABLE IF EXISTS indiv_sample;\n",
    "\n",
    "CREATE TABLE indiv_sample AS\n",
    "SELECT *\n",
    "     FROM individual TABLESAMPLE BERNOULLI(.1) REPEATABLE(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more manual way to construct a random sample of a fixed size.   Note that this is not as efficient taking several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%sql $postgresql_uri\n",
    "\n",
    "# SELECT SETSEED(0.5);\n",
    "\n",
    "# DROP TABLE IF EXISTS indiv_sample2;\n",
    "\n",
    "# CREATE TABLE indiv_sample2 AS\n",
    "# SELECT *, RANDOM() AS u\n",
    "# FROM individual \n",
    "# ORDER BY u\n",
    "# LIMIT 20000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT COUNT(*) FROM indiv_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT * FROM indiv_sample2 LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting rows and columns, and calling scalar (per-row) functions.\n",
    "OK, we already had a peek at the `individual` table. Now let's look at specific attributes (columns) relates to who is donating how much. \n",
    "\n",
    "In addition to referencing the columns of `individual` in the `select` clause, we can also derive new columns by writing field-level (so-called \"scalar\") functions. Typically we reference some table columns in those functions.\n",
    "\n",
    "In our case, let's compute the log of `transaction_amt` for subsequent plotting. SQL comes with many typical functions you can use in this way, and PostgreSQL is particularly rich on this front; see the [PostgreSQL manual](https://www.postgresql.org/docs/9.6/static/functions.html) for details.\n",
    "\n",
    "We'll look at `indiv_sample` rather than `individual` while we're just exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT name, state, cmte_id,\n",
    "       transaction_amt, log(transaction_amt)\n",
    "FROM indiv_sample\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine SQL with python in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT transaction_amt AS amt\n",
    "FROM indiv_sample\n",
    "WHERE transaction_amt > 0;\n",
    "\"\"\"\n",
    "result = %sql $postgresql_uri $query\n",
    "\n",
    "sns.distplot(result.DataFrame()['amt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT LOG(transaction_amt) AS log_amt\n",
    "FROM indiv_sample\n",
    "WHERE transaction_amt > 0;\n",
    "\"\"\"\n",
    "result = %sql $postgresql_uri $query\n",
    "\n",
    "sns.distplot(result.DataFrame()['log_amt'])\n",
    "scales = np.array([1,10,20,  100, 500,  1000, 5000])\n",
    "_ = plt.xticks(np.log10(scales), scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CASE` statements: SQL conditionals in the `FROM` clause\n",
    "What about smaller donations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%sql $postgresql_uri\n",
    "\n",
    "# SELECT name, state, cmte_id,\n",
    "#        transaction_amt, LOG(transaction_amt)\n",
    "# FROM indiv_sample\n",
    "# WHERE transaction_amt < 10\n",
    "# LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, log is not defined for numbers <= 0! We need a *conditional* statement in the `select` clause to decide what function to call. We can use SQL's `case` construct for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT name, state, cmte_id, transaction_amt,\n",
    "    CASE WHEN transaction_amt > 0 THEN log(transaction_amt)\n",
    "         WHEN transaction_amt = 0 THEN 0\n",
    "         ELSE -1*(log(abs(transaction_amt)))\n",
    "    END AS log_magnitude\n",
    "FROM indiv_sample\n",
    "WHERE transaction_amt < 10\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting rows: more interesting `WHERE` clauses\n",
    "We can choose which rows do and do not appear in the query by putting boolean-valued expressions (\"predicates\") in the `WHERE` clause, right after the `FROM` clause. For example, we might be looking for big donations greater than $1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "-- Notice that as we are more selective we return to the fulld ata\n",
    "\n",
    "SELECT name, city, state, transaction_amt\n",
    "FROM individual \n",
    "WHERE transaction_amt > 1000 \n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can form more complex predicates using Boolean connectives AND, OR and NOT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT name, city, state, transaction_amt\n",
    "FROM individual\n",
    "WHERE transaction_amt > 1000\n",
    "    AND (state = 'WI' OR state = 'IL')\n",
    "    AND NOT (city = 'CHICAGO')\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order by\n",
    "\n",
    "Finally by combing ORDER BY and LIMIT we can identify top campaign contributors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT name, ROUND(SUM(transaction_amt)/100.0, 2) total_amt\n",
    "FROM individual\n",
    "WHERE city = 'SAN FRANCISCO'\n",
    "GROUP BY name\n",
    "ORDER BY total_amt DESC\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the combination of `ORDER BY` and `LIMIT 10` gives you the \"top 10\" results. That's often handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the granularity of our `individual` table? Transactions? Examining the schema it doesn't look like there's a key for the donor. Maybe the `image_num` is a key? Or the `file_num`?  \n",
    "\n",
    "To determine this, we need to count up the total number of rows, and the number of *distinct values* that occur in the `image_num` column. SQL provides a family of [*aggregate functions*] for use in the `select` clause. In the simplest form, queries with aggregates in the `select` clause generate a single row of output, with each aggregate function performing a summary of all the rows of input. You can have many aggregate functions in your `select` clause:\n",
    "\n",
    "A list of built-in aggregate functions in PostgreSQL is [here](https://www.postgresql.org/docs/9.6/static/functions-aggregate.html). In our case, the query we are looking for is as follows. To start with, we'll run it on our sample for a sanity check:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Queries: Views and CTEs\n",
    "\n",
    "Up to now we've looked at a single query at a time. SQL also allows us to nest queries in various ways. In this section we look at the cleaner examples of how to do this in SQL: views and Common Table Expressions (CTEs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Views\n",
    "In earlier examples, we created new tables and populated them from the result of queries over stored tables. There are two main drawbacks of that approach that may concern us in some cases:\n",
    "\n",
    "1. The new table **uses up storage**, even though it is recomputable from other tables.\n",
    "1. **Out of date**. The stored output will not reflect changes in the input. \n",
    "\n",
    "For this reason, SQL provides a notion of logical *views*: these are basically named queries that are re-evaluated upon each reference. \n",
    "\n",
    "\n",
    "The syntax is straightforward:\n",
    "\n",
    "```sql\n",
    "CREATE VIEW <name> AS\n",
    "<SELECT statement>;\n",
    "```\n",
    "\n",
    "The resulting view `<name>` can be used in an `SELECT` query, but **not** in an `INSERT`, `DELETE` or `UPDATE` query!\n",
    "\n",
    "As an example, we might want a view that stores just some summary statistics of `transaction_amt`s for each date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "\n",
    "DROP VIEW IF EXISTS date_stats;\n",
    "\n",
    "CREATE VIEW date_stats AS\n",
    "SELECT \n",
    "    to_date(transaction_dt, 'MMDDYYYY') as day, -- Date Parsing\n",
    "    min(transaction_amt), \n",
    "    avg(transaction_amt), \n",
    "    stddev(transaction_amt),\n",
    "    max(transaction_amt)\n",
    "FROM indiv_sample\n",
    "GROUP BY transaction_dt\n",
    "ORDER BY day;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * from date_stats limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that this did not create a table: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"\\dt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instead it created a view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"\\dv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list more about the view using the `\\d+` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql ds100 -c \"\\d+ date_stats\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Views are not materialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a random table and we will even seed the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT setseed(0.3);\n",
    "\n",
    "DROP VIEW IF EXISTS rando;\n",
    "\n",
    "CREATE VIEW rando(rownum, rnd) AS\n",
    "SELECT rownum, round(random())::INTEGER\n",
    "FROM generate_series(1,50) AS ind(rownum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the sum of the rows in Random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT SUM(rnd) FROM rando;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was that value again?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT SUM(rnd) FROM rando;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "</br></br></br>\n",
    "\n",
    "The value changes with each invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too Many Views\n",
    "\n",
    "Views can help:\n",
    "* Simplify queries\n",
    "* Make complex queries more readable \n",
    "* Share \"sql programs\" with others \n",
    "\n",
    "Problem:\n",
    "* Creating a new view for each (exploratory) query will result in a lot of views! \n",
    "* views like: `temp1`, `temp1_joey`, `temp1_joey_fixed`, ... \n",
    "\n",
    "** We need a mechanism to decompose query into views for the scope of a single query.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Table Expressions (`WITH`)\n",
    "\n",
    "Think of these as a view that exists only during the query.\n",
    "\n",
    "If we're only going to use a view within a single query, it is a little inelegant to `CREATE` it, and then have to `DROP` it later to recycle the view name.\n",
    "\n",
    "*Common Table Expressions* (CTEs) are like views that we use on-the-fly. (If you know about lambdas in Python, you can think of CTEs as lambda views.) The syntax for CTEs is to use a `WITH` clause in front of the query: \n",
    "\n",
    "`WITH <name> [(renamed columns)] AS \n",
    "  (<SELECT statement>) \n",
    "  [, <name2> AS (<SELECT statement>)...]`\n",
    "\n",
    "If you need multiple CTEs, you separate them with commas.\n",
    "We can rewrite our query above without a view as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "WITH per_day_stats AS (\n",
    "    SELECT \n",
    "        to_date(transaction_dt, 'MMDDYYYY') as day, -- Date Parsing\n",
    "        min(transaction_amt), \n",
    "        avg(transaction_amt), \n",
    "        stddev(transaction_amt),\n",
    "        max(transaction_amt)\n",
    "    FROM indiv_sample\n",
    "    GROUP BY transaction_dt\n",
    ")    \n",
    "SELECT day, stddev\n",
    "FROM per_day_stats\n",
    "WHERE stddev IS NOT NULL\n",
    "ORDER by stddev DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile Queries on States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql $postgresql_uri\n",
    "\n",
    "SELECT state, \n",
    "       percentile_cont(0.25) WITHIN GROUP (ORDER BY transaction_amt) as lower_quartile,\n",
    "       percentile_cont(0.5) WITHIN GROUP (ORDER BY transaction_amt) as median,\n",
    "       percentile_cont(0.75) WITHIN GROUP (ORDER BY transaction_amt) as upper_quartile\n",
    "FROM indiv_sample\n",
    "GROUP BY state\n",
    "ORDER BY upper_quartile DESC\n",
    "LIMIT 10;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "498px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
